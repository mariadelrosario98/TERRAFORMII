# üìä Taller 3 ‚Äì Miner√≠a de Grandes Vol√∫menes de Datos  
### Benchmark de An√°lisis de Logs a Escala (AWS S3 + EC2)

Este proyecto implementa y compara diferentes enfoques de procesamiento para grandes vol√∫menes de datos alojados en **Amazon S3**, utilizando instancias **EC2** como entorno de ejecuci√≥n.  
El objetivo fue evaluar el rendimiento, uso de memoria y CPU de distintas herramientas anal√≠ticas: **Python**, **Pandas**, **Polars**, **DuckDB** y **Apache Spark**.

---

## üß± 1. Infraestructura y Preparaci√≥n de Datos

### üìÅ Estructura de Datos en S3
Los datos se almacenaron en el bucket:
s3a://terraform-51257688b24ec567/


Cada carpeta representa una carga de trabajo espec√≠fica:

| Folder | Workload | Prop√≥sito |
|---------|-----------|-----------|
| `5gb/`  | 5 GB  | L√≠nea base de rendimiento |
| `10gb/` | 10 GB | Escalabilidad inicial |
| `15gb/` | 15 GB | Rendimiento intermedio |
| `20gb/` | 20 GB | Carga a gran escala |
| `25gb/` | 25 GB | L√≠mite superior del benchmark |

Los archivos `.json` (~94 KB cada uno) contienen arreglos de logs con campos:

- `timestamp` ‚Üí permite calcular tasas de logs por segundo  
- `message` ‚Üí contiene el c√≥digo HTTP (`200`, `404`, `500`)  
- `log_level`, `user_id`, `session_id`, etc.

---

## ‚öôÔ∏è 2. Metodolog√≠a de Implementaci√≥n

Se desarrollaron y compararon dos estrategias principales de procesamiento desde S3.

### üß© Enfoque H√≠brido (Hybrid I/O)
Usado en **Pandas** y **Polars** por problemas de autenticaci√≥n y versi√≥n.  
El flujo fue:

1. Descarga secuencial de archivos con `boto3`.
2. Lectura en memoria (`io.StringIO`).
3. Procesamiento vectorizado con Pandas o Polars.

| Herramienta | Estrategia | Descripci√≥n |
|--------------|-------------|-------------|
| Python / Pandas / Polars | Descarga secuencial + procesamiento vectorizado | Iteraci√≥n lenta v√≠a boto3, luego procesamiento local eficiente. |

### üöÄ Enfoque Nativo (Native S3 I/O)
Intento original de lectura paralela directa desde S3.

| Herramienta | Estrategia | Descripci√≥n |
|--------------|-------------|-------------|
| Polars (original) | Conector S3 integrado + paralelismo | Bloqueado por errores de autenticaci√≥n y formato; se adopt√≥ el enfoque h√≠brido. |

---

## üíª 3. Tutorial: Comandos Esenciales

### üß© Preparaci√≥n del entorno
Cada metodolog√≠a ten√≠a su propio ambiente virtual:

```bash
mkdir -p ~/ex-polars
cd ~/ex-polars
python3.12 -m venv .venv
. .venv/bin/activate
```
##üì¶ Instalaci√≥n de dependencias
# Polars o Pandas
pip install polars boto3
pip install pandas boto3

# Python puro
pip install boto3

# ‚ö° Ejecuci√≥n del Benchmark

Cada prueba se med√≠a con `/usr/bin/time -v`:

```bash
/usr/bin/time -v python main.py s3://[NOMBRE-BUCKET]/[TAMA√ëO-GB]


**Ejemplo (Polars, 10 GB):**

`/usr/bin/time -v python main.py s3://terraform-51257688b24ec567/10gb`
```
* * * * *

üî• 4. Configuraci√≥n de Spark y Conexi√≥n a S3
--------------------------------------------

### 4.1 Soluci√≥n de Incompatibilidad Java / PySpark
```
`pip install pyspark==3.2.4
JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64`
```
### 4.2 Configuraci√≥n de Conectividad a S3

| Par√°metro | Prop√≥sito |
| --- | --- |
| `--packages org.apache.hadoop:hadoop-aws:3.3.1` | Librer√≠as de AWS y Hadoop para S3 |
| `--conf "spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"` | Activa el sistema de archivos S3A |

### 4.3 Permisos de Acceso a M√≥dulos (Java 17)

`--conf "spark.driver.extraJavaOptions=--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\
--add-opens=java.base/java.nio=ALL-UNNAMED\
--add-opens=java.base/jdk.internal.misc=ALL-UNNAMED"`

### 4.4 Ejemplo Final (20 GB)
```
`/usr/bin/time -v env JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64 spark-submit\
  --master local[*]\
  --packages org.apache.hadoop:hadoop-aws:3.3.1\
  --conf "spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem"\
  --conf "spark.driver.extraJavaOptions=--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\
  --add-opens=java.base/java.nio=ALL-UNNAMED\
  --add-opens=java.base/jdk.internal.misc=ALL-UNNAMED"\
  /home/ssm-user/ex-spark/main.py s3a://terraform-51257688b24ec567/20gb`
```
* * * * *

üß† 5. Organizaci√≥n de la Infraestructura
----------------------------------------

Estructura modular por carpetas:

`~/ex-polars/
    ‚îú‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ .venv/
~/ex-pandas/
~/ex-python/
~/ex-spark/`

Cada carpeta tiene su propio entorno virtual (`.venv`) para evitar conflictos de dependencias entre frameworks.

* * * * *

üìà 6. Resultados del Benchmark
------------------------------

| Workload (GB) | Tool | Time (min) | Peak RAM (MB) | Avg CPU (%) |
| --- | --- | --- | --- | --- |
| 5 | Pandas | 6.98 | 2,192 | 12 |
| 5 | Polars | 6.59 | 804 | 7 |
| 5 | Python | 6.21 | 323 | 7 |
| 5 | Spark | 1.60 | 130 | 119 |
| 5 | DuckDB | 1.14 | 126 | 60 |
| 10 | Pandas | 14.42 | 4,297 | 11 |
| 10 | Polars | 12.05 | 563 | 8 |
| 10 | Spark | 2.68 | 1,252 | 155 |
| 10 | DuckDB | 2.35 | 143 | 60 |

* * * * *

üß© 7. Conclusiones del Benchmark
--------------------------------

### ‚ö° Rendimiento Bruto

-   **DuckDB** y **Spark** fueron las herramientas m√°s r√°pidas.

-   Spark mostr√≥ una **escalabilidad casi lineal**: duplicar el tama√±o de los datos duplic√≥ el tiempo de ejecuci√≥n.

### ü¶Ü DuckDB: Procesamiento Vectorizado

-   Motor columnar **OLAP** con lectura directa y eficiente.

-   M√≠nimo uso de **RAM (~150 MB)**.

-   **CPU estable (~60%)** y tiempo bajo.

### üî• Spark: Paralelismo Distribuido

-   Lectura paralela desde S3 y **DAG optimizado**.

-   **CPU entre 119--155%**, aprovechando m√∫ltiples n√∫cleos.

-   Mayor uso de RAM por la **sobrecarga de la JVM**.

### üíæ Sobrecarga JVM e In-Memory Processing

-   La JVM introduce sobrecarga por gesti√≥n de objetos y *garbage collection*.

-   Spark contrarresta esto con *in-memory processing*.

-   El framework **Tungsten** reduce el uso del heap y mejora el rendimiento.

* * * * *

üß™ 8. An√°lisis de la Data
-------------------------

La data sint√©tica generada simula logs de API con distribuci√≥n uniforme:

| C√≥digo HTTP | Proporci√≥n | Interpretaci√≥n |
| --- | --- | --- |
| 2xx | ‚âà 40% | √âxito |
| 4xx | ‚âà 50% | Errores de cliente |
| 5xx | ‚âà 10% | Errores de servidor (cr√≠ticos) |

* * * * *

üìö 9. M√©tricas de Evaluaci√≥n
----------------------------

Las m√©tricas fueron medidas con `/usr/bin/time -v`:

-   **Tiempo total (min)**

-   **Memoria pico (MB)**

-   **CPU promedio (%)**

* * * * *

üßæ Cr√©ditos
-----------

**Autora:**\
Mar√≠a del Rosario Castro Mantilla\
**Universidad EAFIT -- Maestr√≠a en Ciencia de Datos y Anal√≠tica**\
Curso: *Miner√≠a de Grandes Vol√∫menes de Datos -- Taller 3*
